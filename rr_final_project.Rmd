---
title: "Health & Economic Outcomes of Severe Weather Events"
author: "C. McBride"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Synopsis

This report explores the U.S. National Oceanic and Atmospheric Administration's (NOAA) storm dataset, which tracks extreme weather events in the United States, including estimates of any fatalities, injuries, and property damage. These features will be the focus of this report by ranking categories of severe weather events by their consequential material damage and human casualties. 

The data themselves required extensive cleaning and reformatting. Most importantly, the wide-ranging weather event types were gathered into general categories based on similar characteristics such as temperature, percipitation type, storm variety or variations in event naming. The result were more interpretable data that I think supported more meaningful responses to the assignment questions.

While all event categories registered significant and impacts, the events that caused the greatest loss in both terms of life and property were hurricanes, tornados and flooding.


## Data Processing & Exploratory Analysis

The data, in particular the principle variable of interest `EVTYPE`, were inconsistent in their formatting. To correct these inconsistencies in preparation for plotting and addressing the research questions, a series of munging steps were implemented.

__Step 1:__ The requisite libraries are loaded to facilitate analysis and data munging. 

```{r Get Packages, message=FALSE, warning=FALSE}
# load packages
library(choroplethr)
library(choroplethrMaps)
library(dplyr)
library(ggplot2)
library(gtable)
library(knitr)
library(lubridate)
library(maps)
library(readr)
library(reshape2)
library(scales)
library(stringi)
library(xtable)
```

__Step 2:__ The dataset is loaded into the working environment and all possible values of `EVTYPE` are catalogued.

```{r Load Data, message=FALSE, warning=FALSE}
# load compressed data as tibble
noaa <- read_csv("noaa_extreme_weather.csv.bz2")

# get domain of severe weather events
unq <- unique(noaa$EVTYPE)
length(unq)
head(unq)
```

__Step 3:__ After informally cataloging the multitude of weather event types (using `table(noaa$EVTYPE)`), it is advisable not only to clean up the many errors and disparities in the data but also gather the data into categories so that similar events could be examined and assessed collectively. The reasoning here was that similar events often develop under similar conditions and share a profile in terms of damages, for example flooding from heavy rain and flooding from storm surge. To accomplish this, several grouping functions were implemented that rely on regular expressions.

```{r Clean Data, message=FALSE, warning=FALSE}
## clean `EVTYPE` data
# format all levels to uppercase (reduces unique levels by almost 100)
noaa[, "EVTYPE"] <- toupper(noaa$EVTYPE)

# remove summary categories, create dataframe copy
noaa_clean <- noaa[!(stri_detect_regex(noaa$EVTYPE, "SUMMARY")),]

## simplify categories
# find and rename all extreme winter weather events (except snow) under one name
cold <- stri_detect_regex(as.character(noaa_clean$EVTYPE), 
                          "(BLIZZARD|WINT|FREEZE|COLD|ICE|SLEET|ICY)")
noaa_clean[cold, "EVCAT"] <- "COLD"; rm(cold)

# gather all variations of names for hail events under one level name
hail <- stri_detect_regex(as.character(noaa_clean$EVTYPE), "HAIL")
noaa_clean[hail, "EVCAT"] <- "HAIL"; rm(hail)

# all flood related extreme weather events under one level name
flood <- stri_detect_regex(as.character(noaa_clean$EVTYPE),
                           "(FLOOD|TSUNAMI|FLD|HIGH TIDE|SURF|SEICHE|SURGE)")
noaa_clean[flood, "EVCAT"] <- "FLOOD"; rm(flood)

# all major oceanic storms under one level name
hurricane <- stri_detect_regex(as.character(noaa_clean$EVTYPE),
                               "(HURRICANE|TYPHOON|TROPICAL|SURGE)")
noaa_clean[hurricane, "EVCAT"] <- "HURRICANE"; rm(hurricane)

# all thunderstorm and extreme rain under one level name
tstorm <- stri_detect_regex(as.character(noaa_clean$EVTYPE), 
                            "(THUN| TSTM|RAIN|PRECIP)")
noaa_clean[tstorm, "EVCAT"] <- "THUNDERSTORM"; rm(tstorm)

# all extreme heat and drought events under one name
heat_dry <- stri_detect_regex(as.character(noaa_clean$EVTYPE), 
                              "(DROUGHT|DRY|HOT|WARM|HEAT)")
noaa_clean[heat_dry, "EVCAT"] <- "HEAT_DRY"; rm(heat_dry)

# all tornado type events under one level name
tornado <- stri_detect_regex(as.character(noaa_clean$EVTYPE), 
             ("TORNAD|SPOUT|WHIRL|FUNNEL|ROTATING WALL CLOUD|DUST DEVIL"))
noaa_clean[tornado, "EVCAT"] <- "TORNADO"; rm(tornado)

# all extreme wind events (except tornadoes) under one level name
wind <- stri_detect_regex(as.character(noaa_clean$EVTYPE), 
                          "(WIND|BURST|WHIRL)")
noaa_clean[wind, "EVCAT"] <- "WIND"; rm(wind)

# all variations of snow under one level name
snow <- stri_detect_regex(as.character(noaa_clean$EVTYPE), "SNOW")
noaa_clean[snow, "EVCAT"] <- "SNOW"; rm(snow)

# all variations of wildfire descriptions under one level name
fire <- stri_detect_regex(as.character(noaa_clean$EVTYPE), "(FIRE|SMOKE)")
noaa_clean[fire, "EVCAT"] <- "FIRE"; rm(fire)

# all variations of volcano under one level name
volcano <- stri_detect_regex(as.character(noaa_clean$EVTYPE), "VOLCA")
noaa_clean[volcano, "EVCAT"] <- "VOLCANO"; rm(volcano)

# all variations of volcano under one level name
fog<- stri_detect_regex(as.character(noaa_clean$EVTYPE), "FOG")
noaa_clean[fog, "EVCAT"] <- "FOG"; rm(fog)
```

__Step 4:__ Event types that were infrequent or didn't fit within the defined broader categories were eliminated, and event types and categories that were infrequently represented (n < 500) over the entire timespan of the data were not included. 

```{r}
# assign EVTYPE value to EVCAT for those event types that weren't grouped under
# a larger category in previous step
nas <- is.na(noaa_clean$EVCAT)
noaa_clean$EVCAT[nas] <- noaa_clean$EVTYPE[nas]

# remove most infrequent categories
freq_evts <- table(noaa_clean$EVCAT)[table(noaa_clean$EVCAT) > 500]
noaa_clean <- noaa_clean[noaa_clean$EVCAT %in% names(freq_evts),]

# changes to feature classes
noaa_clean[, "EVCAT"] <- as.factor(noaa_clean$EVCAT)
```

__Step 5:__ The numeric codes for `STATE__` and `COUNTY` are formatted and combined into a [FIPS county code][3] for later geographic plotting by county.

```{r Generate FIPS codes}
# COUNTY code formatting function, adds requisite zeros
noaa_clean <- noaa_clean%>%
  mutate(FIPS=as.integer(STATE__ * 1000 + COUNTY))

```

__Step 6:__ To facilitate subsetting the data on the particular dates of exceptional events such as large hurricanes, the date fields `BGN_DATE` and `END_DATE` are transformed form character objects to Date objects.

```{r Format Dates, warning=FALSE, message=FALSE}
# transform date variable from character class to Date class
noaa_clean <- noaa_clean%>%
  mutate(BGN_DATE=as.Date(BGN_DATE, format="%m/%d/%Y %H:%M:%S"),
         END_DATE=as.Date(END_DATE, format="%m/%d/%Y %H:%M:%S"))
```

__Step 7:__ To facilitate geographic plotting, a couple of transformations are made to the data. To be able to plot with choropleths, a variable with the full state name in all lower case is added to the data.

```{r Add full state name, message=FALSE, warning=FALSE}
# Use STATE to create feature with full state name
noaa_clean <- noaa_clean%>%
  mutate(STATENAME=tolower(state.name[match(STATE, state.abb)]))
  
```

In addition, the coordinate values, `LONGITUDE` and `LATITUDE` are cleaned and formatted. Although the data includes events from US territories and the two states outside the contiguous US, the data was further subsetted on the lower 48 states. 

```{r}
## Prepare geographic plot
# correct coordinate format
# format longitude values
frmt_lons <- function(x){ 
  x2 <- x%/%100 + x%%100/100
  if(x2<0){
    return(x2)
  }else{
    return(x2*-1)
  }
}

# format latitude values
frmt_lats <- function(x){ 
  x%/%100 + x%%100/100
}

# Apply functions for coordinal data
noaa_clean$LONGITUDE <- sapply(noaa_clean$LONGITUDE, frmt_lons) 
noaa_clean$LATITUDE <- sapply(noaa_clean$LATITUDE, frmt_lats)

# Further subset coordinate values against bounding box of continental US
noaa_clean <- subset(noaa_clean, STATE %in% state.abb)
```


__Step 8:__ As a preliminary formatting step for examining material damage, an integer estimate of the damages caused by each event is calculated using the coefficient and exponent variable. Observations with anomalous values (e.g. `PROGDMGEXP`="?")  are removed from the dataset.


```{r}
## Calculate damages with PROPDMG and CROPDMG with their exponent variables
# deal with NA's in exponent columns
noaa_clean[is.na(noaa_clean$PROPDMGEXP), 'PROPDMGEXP'] <- "0"
noaa_clean[is.na(noaa_clean$CROPDMGEXP), 'CROPDMGEXP'] <- "0"

# Set up look-up list for transforming exponent variable to numerical
dmg_exps <- list("K"=3, "M"=6, "B"=9, "m"=6, "h"=2, "H"=2, "k"=3)

# Deal with anomalous characters in PROPDMGEXP and CROPDMGEXP
noaa_clean[noaa_clean$PROPDMGEXP %in% c("+", "?", "-"),
           'PROPDMGEXP'] <- "0"
noaa_clean[noaa_clean$CROPDMGEXP %in% c("+", "?", "-"),
           'CROPDMGEXP'] <- "0"

# Transform letter exponent to number
noaa_clean$PROPDMGEXP <- sapply(noaa_clean$PROPDMGEXP,
                                function(e){
                                  ifelse(e %in% names(dmg_exps), 
                                         dmg_exps[[e]], as.numeric(e))
                                })

noaa_clean$CROPDMGEXP <- sapply(noaa_clean$CROPDMGEXP,
                                function(e){
                                  ifelse(e %in% names(dmg_exps), 
                                         dmg_exps[[e]], as.numeric(e))
                                })
# Perform exponent calculations, assign full cost value back to PROPDMG, CROPDMG
noaa_clean <- noaa_clean%>%
  mutate(PROPDMG_TOT=PROPDMG*10^PROPDMGEXP,
         CROPDMG_TOT=CROPDMG*10^CROPDMGEXP,
         YEAR=year(as.Date(BGN_DATE, format="%m/%d/%Y")))
```

__Step 9:__ Because some the data look extreme, a quick summary to test for outliers.

```{r message=FALSE, warning=FALSE}
# Get quantile summaries of damages by event category
qnt_smry <- noaa_clean%>%
  group_by(EVCAT)%>%
  summarize(
            mean=mean(PROPDMG_TOT),
            median=median(PROPDMG_TOT),
            third_qrt=quantile(PROPDMG_TOT, .75), 
            max=max(PROPDMG_TOT))

# summaries table
kable(qnt_smry)

```

Most of the max values deserve some attention event category by category. In the case of `COLD`, the max value for `PROPDMG_TOT` of $5 billion doesn't seem impossible since the event in question was described as the ["Storm of the Century" or the "Blizzard of 1993"][1] in popular culture and categorized as a category 5 storm meteorologically. 

The costliest fire likewise turns out not to be a data error. The [Cerro Grande Fire][2] in northern New Mexico along with other fires across the state caused widespread damage worth over a billion dollars.

The damages caused by a severe hail storm in October of 2010 in Phoenix, Arizona caused close to $2 billion in damages.

The maximum value for `THUNDERSTORM` is probably better moved to the flood category. 

The billion dollar damages recorded for the top tornado belonged to a tornado that tore through Joplin, Missouri.

The maximimum value for `WIND` is actually another instance, albeit geographically unique, for the ["Storm of the Century"][1]. Many of the other extreme property damages value for this category are attributalbe to hurricanes.

```{r warning=FALSE, message=FALSE}
## weather event categories associated with single events
# Hurricane Katrina
katrina <- noaa_clean%>%
  filter(BGN_DATE >= as.Date("2005-08-22") &
         END_DATE <= as.Date("2005-08-28") &
         EVCAT=="HURRICANE" |
         grepl("Katrina", noaa_clean$REMARKS))%>%
  group_by(EVCAT)%>%
  summarise(freq=n())
  
katrina <- cbind(rep("Hurricane Katrina", length(katrina)), 
                     katrina)
names(katrina) <- c("Storm", "Category", "Frequency")

# Joplin Tornado
joplin <- noaa_clean%>%
  filter(BGN_DATE >= as.Date("2011-05-21") &
        END_DATE <= as.Date("2011-05-23") &
        FIPS %in% c(29097, 29145) |
        grepl("Joplin", noaa_clean$REMARKS))%>%
  group_by(EVCAT)%>%
  summarise(freq=n())

joplin <- cbind(rep("Joplin Tornado", nrow(joplin)), 
                     joplin)
names(joplin) <- c("Storm", "Category", "Frequency")

# Storm of Century - Blizzard of 1993
blizzard_93 <- noaa_clean%>%
  filter(BGN_DATE >= as.Date("1993-03-11") &
         BGN_DATE <= as.Date("1993-03-16") &
         STATE %in% c('FL', 'MS', 'AL', 'GA', 'SC', 'NC', 'TN',
                      'KY', 'VA', 'WV', 'IN', 'OH', 'NY', 'PA',
                      'NJ', 'MA', 'ME', 'RI', 'DE', 'CT', 'MD',
                      'VT'))%>%
  group_by(EVCAT)%>%
  summarise(freq=n())  

blizzard_93 <- cbind(rep("Blizzard of 1993", nrow(blizzard_93)), 
                     blizzard_93)
names(blizzard_93) <- c("Storm", "Category", "Frequency")



# Hurricane Camille
camille <- noaa_clean%>%
  filter(BGN_DATE >= as.Date("1969-08-15") &
         BGN_DATE <= as.Date("1969-08-21") &
         STATE %in% c('FL', 'OK', 'WV', 'VA', 'DE',
                      'GA', 'LA', 'MS', 'AL', 'TN', 
                      'KY') |
         grepl("Camille", noaa_clean$REMARKS))%>%
  group_by(EVCAT)%>%
  summarise(freq=n())

camille <- cbind(rep("Hurricane Camille", length(camille)), 
                     camille)
names(camille) <- c("Storm", "Category", "Frequency")

perf_storms <- rbind(katrina, joplin, blizzard_93, camille)%>%
               dcast(Category ~ Storm, value.var = "Frequency", fun=sum)
kable(perf_storms)

```





```{r warning=FALSE, message=FALSE}
# summarize data for test plot
katrina_flood <- noaa_clean%>%
  filter(BGN_DATE >= as.Date("2005-08-22") &
         END_DATE <= as.Date("2005-09-01") &
         grepl("Z.*[>-]", COUNTYNAME))
  group_by(FIPS)%>%
  summarise(value=log(sum(PROPDMG_TOT)+1))


names(katrina_flood)[1] <- "region"


# test plot of FIPS data
katrina_flood <- CountyChoropleth$new(katrina_flood)
katrina_flood$set_num_colors(5)
katrina_flood$ggplot_scale <- scale_fill_brewer(palette = "YlOrRd", guide = FALSE)
katrina_flood$set_zoom(c("alabama", "louisiana", "mississippi", "tennessee", "kentucky"))


katrina_flood$render_with_reference_map()
plot(pfz_la, col=pfz_la$COLOR)
  # geom_path(data=kat_path, mapping=aes(lon*-1, lat), size=2, color="grey50",
  #           linetype=2, alpha=.5, show.legend = FALSE)+
  labs(caption="Flood Related")+
  theme(plot.caption = element_text(hjust = 0.5, size=14))
  # plot(pfz_la, col=pfz_la$COLOR)
```

```{r warning=FALSE}
# summarize data for test plot
katrina_wind <- noaa_clean%>%
  filter(BGN_DATE >= as.Date("2005-08-22") &
         END_DATE <= as.Date("2005-09-01") &
         EVCAT=="WIND")%>%
  group_by(STATENAME)%>%
  summarise(value=log(sum(PROPDMG_TOT)+1))

names(katrina_wind)[1] <- "region"


# test plot of FIPS data
katrina_wind <- StateChoropleth$new(katrina_wind)
katrina_wind$set_num_colors(5)
katrina_wind$ggplot_scale <- scale_fill_brewer(palette = "YlOrRd", guide = FALSE)
katrina_wind$set_zoom(c("alabama", "louisiana", "mississippi", "tennessee", "kentucky"))



kat_plt2 <- katrina_wind$render_with_reference_map()+
  geom_path(data=kat_path, mapping=aes(lon*-1, lat), size=2, color="grey50",
            linetype=2, alpha=.5, show.legend = FALSE)+
  labs(caption="Wind Related")+
  theme(plot.caption = element_text(hjust = 0.5, size = 14))
```

```{r, message=FALSE, warning=FALSE}
library(gridExtra)
library(grid)
grid.arrange(kat_plt1, kat_plt2, ncol=2, 
             top=textGrob(
               "Relative Material Damage by State of Hurricane Katrina",
               gp=gpar(fontsize=16,font=3)))
```


```{r warning=FALSE, message=FALSE}
# vector of affected states
af_sts <- c("alabama",  "connecticut", "delaware", "florida", "georgia",
                    "kentucky", "louisiana", "maine", "maryland", "massachusetts",
                    "mississippi", "new hampshire",  "new jersey", "new york",
                    "north carolina", "pennsylvania", "south carolina",
                    "tennessee", "vermont", "virginia", "west virginia")

# summarize data for test plot
blizzard_93_flood <- noaa_clean%>%
  filter(BGN_DATE >= as.Date("1993-03-11") & 
           BGN_DATE <= as.Date("1993-03-15") &
           STATENAME %in% af_sts &
           EVCAT=="FLOOD")%>%
  group_by(STATENAME)%>%
  summarise(value=log(sum(PROPDMG_TOT)+1))

names(blizzard_93_flood)[1] <- "region"


# test plot of FIPS data
blizzard_93_flood <- StateChoropleth$new(blizzard_93_flood)
blizzard_93_flood$set_num_colors(9)
blizzard_93_flood$ggplot_scale <- scale_fill_brewer(palette = "YlOrRd", 
                                                    guide = FALSE)
blizzard_93_flood$set_zoom(af_sts) 
blz_93_plt1 <- blizzard_93_flood$render_with_reference_map()

```

```{r message=FALSE, warning=FALSE}
# summarize data for test plot
blizzard_93_wind <- noaa_clean%>%
  filter(BGN_DATE >= as.Date("1993-03-11") & 
           BGN_DATE <= as.Date("1993-03-15") &
           STATENAME %in% af_sts &
           EVCAT=="WIND")%>%
  group_by(STATENAME)%>%
  summarise(value=log(sum(PROPDMG_TOT)+1))

names(blizzard_93_wind)[1] <- "region"


# test plot of FIPS data
blizzard_93_wind <- StateChoropleth$new(blizzard_93_wind)
blizzard_93_wind$set_num_colors(9)
blizzard_93_wind$ggplot_scale <- scale_fill_brewer(palette = "YlOrRd", 
                                                    guide = FALSE)
blizzard_93_wind$set_zoom(af_sts) 
blz_93_plt2 <- blizzard_93_wind$render_with_reference_map()
```


```{r message=FALSE, warning=FALSE}
# summarize data for test plot
blizzard_93_snow <- noaa_clean%>%
  filter(BGN_DATE >= as.Date("1993-03-11") & 
           BGN_DATE <= as.Date("1993-03-15") &
           STATENAME %in% af_sts &
           EVCAT=="SNOW")%>%
  group_by(STATENAME)%>%
  summarise(value=log(sum(PROPDMG_TOT)+1))

names(blizzard_93_snow)[1] <- "region"


# test plot of FIPS data
blizzard_93_snow <- StateChoropleth$new(blizzard_93_snow)
blizzard_93_snow$set_num_colors(9)
blizzard_93_snow$ggplot_scale <- scale_fill_brewer(palette = "YlOrRd", 
                                                    guide = FALSE)
blizzard_93_snow$set_zoom(af_sts) 
blz_93_plt3 <- blizzard_93_snow$render_with_reference_map()
```

```{r message=FALSE, warning=FALSE}
# summarize data for test plot
blizzard_93_tor <- noaa_clean%>%
  filter(BGN_DATE >= as.Date("1993-03-11") & 
           BGN_DATE <= as.Date("1993-03-15") &
           STATENAME %in% af_sts &
           EVCAT=="TORNADO")%>%
  group_by(STATENAME)%>%
  summarise(value=log(sum(PROPDMG_TOT)+1))

names(blizzard_93_tor)[1] <- "region"


# test plot of FIPS data
blizzard_93_tor <- StateChoropleth$new(blizzard_93_tor)
blizzard_93_tor$set_num_colors(9)
blizzard_93_tor$ggplot_scale <- scale_fill_brewer(palette = "YlOrRd", 
                                                    guide = FALSE)
blizzard_93_tor$set_zoom(af_sts) 
blz_93_plt4 <- blizzard_93_tor$render_with_reference_map()
```

```{r, message=FALSE, warning=FALSE}
grid.arrange(blz_93_plt1, blz_93_plt2, ncol=2, 
             top=textGrob(
               "Relative Material Damage by State of Blizzard of 1993",
               gp=gpar(fontsize=16,font=3)))

```

__Step 6:__ Next, the data was grouped by category, and counts for fatalities and injuries were calculated. 

```{r}
# group data by EVCAT and get total fatalities, injuries for each category
smry_fatals <- noaa_clean%>%
  group_by(EVCAT)%>%
  summarize(tot_fatals=sum(FATALITIES),
            tot_injuries=sum(INJURIES))%>%
  melt(id.vars='EVCAT', measure.vars=c('tot_fatals', 
                                       'tot_injuries'),
       variable.name="type", value.name = "value")%>%
  arrange(type, desc(value))

# Change levle order in prep for sorted bar plot
smry_fatals$EVCAT <- factor(smry_fatals$EVCAT, 
                            levels=smry_fatals$EVCAT[14:26])
```

__Step 6:__ Using the grouped and summarized data, a bar plot is made comparing the two classes of casualties by event category.









__Step 9:__ Next, the same grouping and summarizing is performed on the data this time grouping the data by EVCAT and YEAR and getting the mean property and crop damage.

```{r}
# Group data by event category and year, summarize by property and crop totals
smry_dmgs <- noaa_clean%>%
  group_by(EVCAT, YEAR)%>%
  summarize(tot_prop=mean(PROPDMG_TOT),
            tot_crop=mean(CROPDMG_TOT))%>%
  filter(tot_prop > 0 & tot_crop > 0)%>%
  melt(id.vars=c('EVCAT', 'YEAR'), measure.vars=c('tot_prop', 'tot_crop'),
       variable.name="type", value.name = "value")%>%
  arrange(type, desc(value))

```
 
__Step 10:__ 

```{r error=FALSE, message=FALSE, warning=FALSE}

```



__Step 12:__ 




## Results & Conclusions

The first research question was answered visually by plotting the aggregate casualty figures per generated category. The values for the most deadly weather categories so exaggerated the y-axis that a log-scale was used so that the bars for the other categries would be apparent. The most deadly categories of severe weather were tornadoes, perhaps because they are largely unpredictable both in terms of occurrence and location besides being so destructive. Other very deadly weather categories included flooding, extremely dry and hot weather, along with strong wind. The plot below compares the deadliness of severe weather categories both in terms of fatalities and injuries. 

```{r echo=FALSE}

```

```{r echo=FALSE}


  
```


What stood out most in the analysis of the casualties and damages data was incredibly high material cost associated with severe weather, both summatively and by individual event category. I was incredulous (and still am to some degree) with the summaries the analysis produced since the aggregate annual damages sometimes reach into the trillions of dollars.

Fortunately, the injuries and loss of life figures did not seem as inflated as the material losses. While some particular events, such as major hurricanes caused noticeable spikes in the data, the mean casualty rate for most of the generated event categories was around one.

## Citations & Links

[1]: https://en.wikipedia.org/wiki/1993_Storm_of_the_Century

[2]: https://en.wikipedia.org/wiki/Cerro_Grande_Fire

[3]: https://en.wikipedia.org/wiki/FIPS_county_code